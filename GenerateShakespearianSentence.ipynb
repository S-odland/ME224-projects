{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myhw20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-odland/ME224-projects/blob/master/GenerateShakespearianSentence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr264GCP0eaE"
      },
      "source": [
        "# 2020 224 Lesson 20 Homework Template\n",
        "\n",
        "This is a continutaton of homework 19.   If you were not as successful as you hoped with finding sentences (removing stage directions and glop) in homework 19, you may prefer to start from a decent list of sentences now.  Here's one, [shakespeare_sentences.txt](https://drive.google.com/file/d/1upt4cwcW61awaUfdo9rEBxM0cfSpnAXK/view?usp=sharing). This file has original capitalization, but all the punctuation except apostophes inside words has been removed.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjMg7sQxcNHm"
      },
      "source": [
        "### My Implementation/Though Process\n",
        "\n",
        "The way I worked through this problem was by first creating a dictionary of words in the first 500 sentences of shakespeare's texts with the number of times each word appeared in the text as the value to the key in the dictionary. \n",
        "\n",
        "Then I created 3 lists of words corresponding to the amount of times each word was mentioned:\n",
        "\n",
        "`unique_words` : word was only said once\n",
        "\n",
        "`common_words`: words between 2 and 50 mentions\n",
        "\n",
        "`unique_words`: words over 50 mentions\n",
        "\n",
        "\n",
        "I think made a for loop and put words in from each list different amounts and at different times and the sentence sometimes sounds coherent. The full code can be ran at the bottom in the last cell, but it doesn't have the colab drive authentication code. That needs to be ran right below this text cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcAwym--BHcS"
      },
      "source": [
        "from google.colab import drive    # this is the basic drive access module\n",
        "\n",
        "drive.mount('/content/drive')   # authenticates at this step, if needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jLE2I6ngJuz"
      },
      "source": [
        "below is my homeworks 19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJLpVeHuB_ya"
      },
      "source": [
        "def make_sentences():\n",
        "  \n",
        "  fread = open('/content/drive/My Drive/data/shakespeare_completeworks.txt', 'r')   # opens shakespeare text for 'read only'\n",
        "  sentences = []\n",
        "  s = ''\n",
        "  stripped_lines = []\n",
        "  new_lines = []\n",
        "  k = 0\n",
        "\n",
        "  while(1):\n",
        "    line = fread.readline()\n",
        "    stripped_lines.append(line.strip('1''2''3''\\n''4''5''6''7''8''9''Enter''Exit''exit''enter''Re-enter''Exeunt'))\n",
        "    if line == '':\n",
        "      break\n",
        "\n",
        "  for i in range (len(stripped_lines)):\n",
        "    for j in range(len(stripped_lines[i])):\n",
        "      if not stripped_lines[i][j].isspace():\n",
        "        k += 1\n",
        "\n",
        "    if stripped_lines[i] != '':\n",
        "      if k > 0:\n",
        "        new_lines.append(stripped_lines[i])\n",
        "\n",
        "  first_3h = []\n",
        "  for i in range(10000,10300):\n",
        "    first_3h.append(stripped_lines[i])\n",
        "\n",
        "  first_3hn = []\n",
        "  for i in range(10000,10300):\n",
        "    first_3hn.append(new_lines[i])\n",
        "\n",
        "  for j in range(len(new_lines)):\n",
        "    line = new_lines[j]\n",
        "    for i in range(len(line)):\n",
        "      if i+1 > len(line) - 1:\n",
        "        if line[i] == '.' or line[i] == '?' or line[i] == '!':\n",
        "          s = s + line[i]\n",
        "          sentences.append(s)\n",
        "          s = ''\n",
        "        else:\n",
        "          s = s + line[i]      \n",
        "      elif line[i].isupper() and (line[i+1].isupper() or line[i+1] == '.' or (line[i+1] == ' ' and line[i-1].isupper())):\n",
        "        continue\n",
        "      elif line[i] == '[':\n",
        "        sentences.append(s)\n",
        "        s = ''\n",
        "        break\n",
        "      elif (line[i-1] == ' ' and line[i] == 'I' and line[i+1] == ' ') and (line[i-1] == ' ' and line[i] == 'A' and line[i+1] == ' '):\n",
        "        s = s + line[i]\n",
        "      else:\n",
        "        if line[i] == '.' or line[i] == '?' or line[i] == '!':\n",
        "          s = s + line[i]\n",
        "          sentences.append(s)\n",
        "          s = ''\n",
        "        else:\n",
        "          s = s + line[i]\n",
        "\n",
        "  m = 0\n",
        "  ss = []\n",
        "  for i in range(len(sentences)):\n",
        "    for j in range(len(sentences[i])):\n",
        "      if sentences[i][j].isalpha():\n",
        "        m += 1\n",
        "    if m > 0:\n",
        "      ss.append(sentences[i])\n",
        "    m = 0\n",
        "  \n",
        "  return ss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fPmJSd3gC7A"
      },
      "source": [
        "below gives the sentences stripped of punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYoCfNBzBZ5L"
      },
      "source": [
        "# this cell gets rid of punctuation except for ' and `\n",
        "\n",
        "def strip_punct(ss):\n",
        "\n",
        "  stripped_ss = []\n",
        "  sentence = ''\n",
        "  for i in range(len(ss)):\n",
        "    for j in range(len(ss[i])):\n",
        "      if ss[i][j].isalpha() or ss[i][j].isspace() or ss[i][j] == \"'\" or ss[i][j] == \"`\":\n",
        "        sentence = sentence + ss[i][j]\n",
        "    stripped_ss.append(sentence)\n",
        "    sentence = ''\n",
        "\n",
        "  return stripped_ss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHjVb9-Pf8Tm"
      },
      "source": [
        "below gives the list of words in the first 500 sentences of shakespeare's texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oML1z1VLO0V8"
      },
      "source": [
        "def get_words(stripped_ss):\n",
        "  \n",
        "  word_list = []\n",
        "  sentence = ''\n",
        "  words = []\n",
        "\n",
        "  for i in range(500):\n",
        "    word_list.append(stripped_ss[i].split(' '))\n",
        "\n",
        "  for i in range(len(word_list)):\n",
        "    for j in range(len(word_list[i])):\n",
        "      if word_list[i][j] != '':\n",
        "        words.append(word_list[i][j])\n",
        "  \n",
        "  return words\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhrrARj4f3be"
      },
      "source": [
        "Below generates list of common, frequent and unique words and makes the word dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54UDKYMj-XnB"
      },
      "source": [
        "from collections import OrderedDict \n",
        "import random\n",
        "\n",
        "def word_freqs(words):\n",
        "\n",
        "    word_freq_dict = {'start':0}\n",
        "\n",
        "    for word in words:\n",
        "      if word not in word_freq_dict.keys():\n",
        "        word_freq_dict[word] = 1\n",
        "      else:\n",
        "        word_freq_dict[word] += 1\n",
        "\n",
        "    freq_words = []\n",
        "    unique_words = []\n",
        "    common_words = []\n",
        "    for key in word_freq_dict:\n",
        "      if word_freq_dict[key] > 50:\n",
        "        freq_words.append(key)\n",
        "      elif word_freq_dict[key] < 2:\n",
        "        unique_words.append(key)\n",
        "      else:\n",
        "        common_words.append(key)\n",
        "\n",
        "    return freq_words,common_words,unique_words\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmmRJXu9fy4l"
      },
      "source": [
        "Below is the sentence generating cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cOFKuo1ZIO6"
      },
      "source": [
        "def generate_sentence(freq_words,common_words,unique_words):\n",
        "\n",
        "  asentence = ''\n",
        "  for i in range(25):\n",
        "    if i == 0:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i < 3 and i > 1:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 3:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i == 4:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "    if i > 4 and i < 6:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 6:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i == 7:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "    if i > 7 and i < 9:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i >= 9 and i < 11:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "    if i == 11:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i > 11 and i < 13:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 13:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i == 14:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "    if i > 14 and i < 16:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 16:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "    if i == 17:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i > 17 and i < 19:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 19:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i > 19 and i < 21:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 21:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "    if i == 22:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i > 22 and i < 24:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 24:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "\n",
        "  print(asentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRLBvR-7jMeq"
      },
      "source": [
        "make_sentences takes a minute so I put it in a different cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GayDJh8kjARt"
      },
      "source": [
        "sents = make_sentences()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKvf1w3AhcXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a5542af-29b8-40ad-87ec-e80d60dc3a87"
      },
      "source": [
        "wordFrequencies = word_freqs(get_words(strip_punct(sents)))\n",
        "generate_sentence(wordFrequencies[0],wordFrequencies[1],wordFrequencies[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " And mark For falls th are olives faces darling prevent'st I objects a recounting twain compass his didst you lies Herein mine ever linger\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqDGjUMgjxW-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e05bb82-8698-42cd-fe3d-0f692d699590"
      },
      "source": [
        "def make_sentences():\n",
        "  \n",
        "  fread = open('/content/drive/My Drive/data/shakespeare_completeworks.txt', 'r')   # opens shakespeare text for 'read only'\n",
        "  sentences = []\n",
        "  s = ''\n",
        "  stripped_lines = []\n",
        "  new_lines = []\n",
        "  k = 0\n",
        "\n",
        "  while(1):\n",
        "    line = fread.readline()\n",
        "    stripped_lines.append(line.strip('1''2''3''\\n''4''5''6''7''8''9''Enter''Exit''exit''enter''Re-enter''Exeunt'))\n",
        "    if line == '':\n",
        "      break\n",
        "\n",
        "  for i in range (len(stripped_lines)):\n",
        "    for j in range(len(stripped_lines[i])):\n",
        "      if not stripped_lines[i][j].isspace():\n",
        "        k += 1\n",
        "\n",
        "    if stripped_lines[i] != '':\n",
        "      if k > 0:\n",
        "        new_lines.append(stripped_lines[i])\n",
        "\n",
        "  first_3h = []\n",
        "  for i in range(10000,10300):\n",
        "    first_3h.append(stripped_lines[i])\n",
        "\n",
        "  first_3hn = []\n",
        "  for i in range(10000,10300):\n",
        "    first_3hn.append(new_lines[i])\n",
        "\n",
        "  for j in range(len(new_lines)):\n",
        "    line = new_lines[j]\n",
        "    for i in range(len(line)):\n",
        "      if i+1 > len(line) - 1:\n",
        "        if line[i] == '.' or line[i] == '?' or line[i] == '!':\n",
        "          s = s + line[i]\n",
        "          sentences.append(s)\n",
        "          s = ''\n",
        "        else:\n",
        "          s = s + line[i]      \n",
        "      elif line[i].isupper() and (line[i+1].isupper() or line[i+1] == '.' or (line[i+1] == ' ' and line[i-1].isupper())):\n",
        "        continue\n",
        "      elif line[i] == '[':\n",
        "        sentences.append(s)\n",
        "        s = ''\n",
        "        break\n",
        "      elif (line[i-1] == ' ' and line[i] == 'I' and line[i+1] == ' ') and (line[i-1] == ' ' and line[i] == 'A' and line[i+1] == ' '):\n",
        "        s = s + line[i]\n",
        "      else:\n",
        "        if line[i] == '.' or line[i] == '?' or line[i] == '!':\n",
        "          s = s + line[i]\n",
        "          sentences.append(s)\n",
        "          s = ''\n",
        "        else:\n",
        "          s = s + line[i]\n",
        "\n",
        "  m = 0\n",
        "  ss = []\n",
        "  for i in range(len(sentences)):\n",
        "    for j in range(len(sentences[i])):\n",
        "      if sentences[i][j].isalpha():\n",
        "        m += 1\n",
        "    if m > 0:\n",
        "      ss.append(sentences[i])\n",
        "    m = 0\n",
        "  \n",
        "  return ss\n",
        "\n",
        "\n",
        "def strip_punct(ss):\n",
        "\n",
        "  stripped_ss = []\n",
        "  sentence = ''\n",
        "  for i in range(len(ss)):\n",
        "    for j in range(len(ss[i])):\n",
        "      if ss[i][j].isalpha() or ss[i][j].isspace() or ss[i][j] == \"'\" or ss[i][j] == \"`\":\n",
        "        sentence = sentence + ss[i][j]\n",
        "    stripped_ss.append(sentence)\n",
        "    sentence = ''\n",
        "\n",
        "  return stripped_ss\n",
        "\n",
        "def get_words(stripped_ss):\n",
        "  \n",
        "  word_list = []\n",
        "  sentence = ''\n",
        "  words = []\n",
        "\n",
        "  for i in range(500):\n",
        "    word_list.append(stripped_ss[i].split(' '))\n",
        "\n",
        "  for i in range(len(word_list)):\n",
        "    for j in range(len(word_list[i])):\n",
        "      if word_list[i][j] != '':\n",
        "        words.append(word_list[i][j])\n",
        "  \n",
        "  return words\n",
        "\n",
        "from collections import OrderedDict \n",
        "import random\n",
        "\n",
        "def word_freqs(words):\n",
        "\n",
        "    word_freq_dict = {'start':0}\n",
        "\n",
        "    for word in words:\n",
        "      if word not in word_freq_dict.keys():\n",
        "        word_freq_dict[word] = 1\n",
        "      else:\n",
        "        word_freq_dict[word] += 1\n",
        "\n",
        "    freq_words = []\n",
        "    unique_words = []\n",
        "    common_words = []\n",
        "    for key in word_freq_dict:\n",
        "      if word_freq_dict[key] > 50:\n",
        "        freq_words.append(key)\n",
        "      elif word_freq_dict[key] < 2:\n",
        "        unique_words.append(key)\n",
        "      else:\n",
        "        common_words.append(key)\n",
        "\n",
        "    return freq_words,common_words,unique_words\n",
        "\n",
        "def generate_sentence(freq_words,common_words,unique_words):\n",
        "\n",
        "  asentence = ''\n",
        "  for i in range(25):\n",
        "    if i == 0:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i < 3 and i > 1:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 3:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i == 4:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "    if i > 4 and i < 6:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 6:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i == 7:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "    if i > 7 and i < 9:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i >= 9 and i < 11:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "    if i == 11:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i > 11 and i < 13:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 13:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i == 14:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "    if i > 14 and i < 16:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 16:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "    if i == 17:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i > 17 and i < 19:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 19:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i > 19 and i < 21:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 21:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "    if i == 22:\n",
        "      ran = random.randint(0,len(freq_words)-1)\n",
        "      asentence = asentence + ' ' + freq_words[ran]\n",
        "    if i > 22 and i < 24:\n",
        "      ran = random.randint(0,len(common_words)-1)\n",
        "      asentence = asentence + ' ' + common_words[ran]\n",
        "    if i == 24:\n",
        "      ran = random.randint(0,len(unique_words)-1)\n",
        "      asentence = asentence + ' ' + unique_words[ran]\n",
        "\n",
        "  print(asentence)\n",
        "\n",
        "sents = make_sentences()\n",
        "wordFrequencies = word_freqs(get_words(strip_punct(sents)))\n",
        "generate_sentence(wordFrequencies[0],wordFrequencies[1],wordFrequencies[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " for lines be share scythe more sell height merits blazon are masked for matcheth past Whereon mine horse have loves older will Fortune's expire\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}